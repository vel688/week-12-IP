---
title: "velvin-week12-ip"
author: "Velsamkul"
date: "4/6/2021"
output: html_document
---

# Research Question

>A Kenyan entrepreneur has created an online cryptography course and would wantto advertise it on her blog. She currently targets audiences originating from various countries. In the past, she ran ads to advertise a related course on the same blog and collected data in the process. She would now like to employ your services as a Data Science Consultant to help her identify which individuals are most likely to click on her ads. 

## 1.a) Specifying the Question 

> To carry out data cleaning and exploratory data analysis
To identify which individuals are most likely to click on the ads of a kenyan entrepreneur based on the given data and come up with recommendations.


##b) Defining the metric for success

> Success will have been achieved when  I complete exploratory data analysis,
 have clear plots and finaly identify individuals who are likely to click on ads


##c) Recording the Experimental Design

> 1. Loading the data
2. Checking the data
3. Tidying the data
4. Univariate Analysis
5. Bivariate Analysis
6. Challenging the solution
7. Recommendations
8. Follow up questions

##4 Checking Data Relevance

> The data provided was found to be  relevant for our analysis because it contains values that are useful.


## 2.Loading and reading Our Datasets
```{r}
library(tidyverse)
```


```{r}
ads <- read.csv("C:/Users/Admin/Downloads/advertising.csv")
view(ads)
```

*Checking the data summary* 
```{r}
summary(ads)
```
The measures of central tendencies are displayed for every column as shown above

*Checking top and bottom rows and columns*
```{r}
tail(ads)
```
```{r}
head(ads)
```

*Checking the classes*
```{r}
class(ads)
```
*Checking the number of rows and in our dataset*
```{r}
cat("Rows in dataset:", nrow(ads), "\nCols in dataset:", ncol(ads))
cat("\nThe dimension of the dataset is:", dim(ads))
```
*Range of Time Spent on Site by users*

```{r}
site.time.range <- range(ads$Daily.Time.Spent.on.Site)
cat("The Range of Time Spent on Site by users is:",site.time.range)
```
*Range of Daily Internet Usage*

```{r}
internet.time.range <- range(ads$Daily.Internet.Usage)
cat("The Range of Daily Internet Usage is:", internet.time.range)
```
*Range of Age*
```{r}
age.range <- range(ads$Age)
cat("The Range of Users' age is:",age.range)
```
*Range of Income*
```{r}
income.range <- range(ads$Area.Income)
cat("The Range of Users' income is:",income.range)
```

*Structure of our dataframe*
```{r}
str(ads)
```
#There are 1000 records and 10 variables. 3 variables of tye numeric, 3 integer types, 4 character types including the date and time which will be converted to the standard format.

*Converting the date and time*
```{r}
class(ads$Timestamp)
```

```{r}
ads$Timestamp <- strptime(paste( ads$Timestamp), format = "%Y-%m-%d %H:%M:%S",tz="UTC") 
class(ads$Timestamp)
```
*Checking for outliers on the numerical columns using boxplots*


```{r}
boxplot(ads$Area.Income)
boxplot(ads$Daily.Time.Spent.on.Site)
boxplot(ads$Age)
boxplot(ads$Daily.Internet.Usage)
```
Only Area   had outliers, Area.

*Dealing with outliers;*

```{r}
bench <- 47032 - 1.5 * IQR(ads$Area.Income) 
ads$Area.Income[ads$Area.Income < bench]<- bench

boxplot(ads$Area.Income)
```
The boxplot shows that the outliers in that column have been removed.

*Checking for duplicates*

```{r}
sum(duplicated(ads))

```
There are no duplicates in our data

*Checking for missing values*
```{r}
colSums(is.na(ads))
```
The dataset has no missing values in any of the columns.

# Exploratory Data Analysis

```{r}
install.packages("dataMaid", repos = "http://cran.us.r-project.org")
install.packages("inspectdf", repos = "http://cran.us.r-project.org")

```
*Calling the libraries*
```{r}
library(dplyr)
library(inspectdf)
```
The 2 packages will give us more insights on our data.

```{r}
inspect_cat(ads)

```
**common_pcnt**, the percentage of each column occupied by the most common level shown in **common.**

## Bivariate Analysis visualization


check for correlation between the different columns and the target variable Clicked.On.Ad.

```{r}
inspect_cor(ads, df2 = NULL, method = "pearson", with_col = 'Clicked.on.Ad', alpha = 0.05)

```
The summary above shows  Pearson's correlation coefficients for all the numeric columns, compared against the 'Clicked.On.Ads' column. 
Tere are negative correlation values for 'Daily.Internet.Usage', 'Daily.Time.Spent.on.Site', 'Area Income'. The only positive correlation is between Clicked.On.Ad' and 'Age'. Generally, there is high correlation.

```{r}
inspect_cor(ads, df2 = NULL, method = "pearson", alpha = 0.05)
```
```{r}
install.packages("PerformanceAnalytics")
install.packages("corrplot")
```
```{r}
library(corrplot)
ads_num <- Filter(is.numeric, ads)
corrplot(cor(ads_num))
```

We plan on using the *Clicked.On.Ad* feature to determine fill colors for these graphs, but that won't work if they stay as they're currently set (integer data type). I'll change that in the following code chunk.

```{r}
library(ggplot2)

ggplot(data = ads, aes(x = Age, fill = Clicked.on.Ad))+
    geom_histogram(bins = 27, color = 'cyan') + 
    labs(title = 'Age distribution with Ad clicks', x = 'Age', y = 'Frequency', fill = 'Clicked.on.Ad') +
        scale_color_brewer(palette = 'Set2') 
      
```

**Income and Click on Ad distribution**
```{r}
ggplot(data = ads, aes(x = Area.Income, fill = Clicked.on.Ad))+
    geom_histogram(bins = 20, color = 'cyan') + 
    labs(title = 'Income distribution', x = 'Income', y = 'Frequency', fill = 'Clicked.on.Ad') +
        scale_color_brewer(palette = 'Set1') 
        
```
**Daily Internet Use and the clicked on ad relationship**

```{r}
ggplot(data = ads, aes(x = Daily.Internet.Usage, fill = Clicked.on.Ad))+
    geom_histogram(bins = 35, color = 'cyan') + 
    labs(title = 'Daily Internet Use distribution', x = 'Daily Internet Usage (minutes)', y = 'Frequency', fill = 'Clicked.on.Ad') +
        scale_color_brewer(palette = 'Set1')
```

**Daily Time Spent on Site and the clicked on ad relationship**
```{r}

ggplot(data = ads, aes(x = Daily.Time.Spent.on.Site, fill = Clicked.on.Ad))+
    geom_histogram(bins = 25, color = 'cyan') + 
    labs(title = 'Daily Time Spent On Site', x = 'Time Spent(minutes)', y = 'Frequency', fill = 'Clicked.on.Ad') +
        scale_color_brewer(palette = 'Set1') 



```

**Daily Time Spent on Site and the Income relationship**
```{r}
ggplot(data = ads, aes(x =Area.Income , fill = Daily.Time.Spent.on.Site))+
    geom_histogram(bins = 30, color = 'cyan') + 
    labs(title = 'Daily Time Spent On Site vs Income', x = 'Income', y = 'Frequency', fill = 'Clicked.on.Ad') +
        scale_color_brewer(palette = 'Set1') 

```

**Daily Time Spent on Site and the Users' Age relationship**
```{r}
ggplot(data = ads, aes(x =Age , fill = Daily.Time.Spent.on.Site))+
    geom_histogram(bins = 30, color = 'cyan') + 
    labs(title = 'Daily Time Spent On Site vs Age', x = 'Age', y = 'Frequency', fill = 'Clicked.on.Ad') +
        scale_color_brewer(palette = 'Set1') 
```


**Daily Internet Usage per Country**
```{r}
ads %>% group_by(Country, Daily.Internet.Usage)%>% head(10)%>% arrange(desc(Daily.Internet.Usage))
```


**Daily Time Spent on Site per Country**
```{r}
ads %>% group_by(Country, Daily.Time.Spent.on.Site)%>% head(10)%>% arrange(desc(Daily.Time.Spent.on.Site))
```

People aged 33 seem to spend the most time on site therefore using the most internet.

#In Conclusion
33year olds spend the most time on the site, generally people in their late 20's till 33years old.
People with higher income spend more time on the sight compared to the less income eraners

#Rcommendation
age had the highest value of a positive  Pearson correlation. It is recommended that the client prioritizes people aged between 29-33 and bear this is mind as they strategise on marketing their products. 

This project has been a success.